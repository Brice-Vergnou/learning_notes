# Linear algebra

=> Link <https://www.coursera.org/learn/linear-algebra-machine-learning?specialization=mathematics-machine-learning>

Week 1:

* Simple introduction to the topic, and explained how vectors work.
* Several homework to practice

Week 2:

* dot product x'x + yy'
* r.s = |r| |s| cosÂ¤ 
* Projection a bit unclear
* Proj_v u = (u.v)/(||v^2||) * v
* v in b basis -> each coef = proj_v b_i

Week 3:
* Matrices transform space
* Finding the inverse of a matrix can be done easily with Gaussian elimination (try to get your matrix A to I with elimination and back-substitution)

Week 4:
* Get a vector in my basis : other matrix basis * vector in our basis => multiply the inverse matrix by the result
* Didn't get Gram-Schmidt process

Week 5:
* Eigenvector -> follow the same span
* Eigenvalue -> How much the vector is scaled
* go too fast
* ax = lx => (a-lx) = 0 => det(a-lx)=0 => l^2 - (a+d)l + ad - bc = 0
![image](https://user-images.githubusercontent.com/86613710/162640602-a9c9ece6-f537-4099-a51b-1c3744d4f3b8.png)
